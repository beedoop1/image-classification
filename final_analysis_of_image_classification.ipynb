{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1j0mZnAsTWIHLuDa91dkT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beedoop1/image-classification/blob/main/final_analysis_of_image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n"
      ],
      "metadata": {
        "id": "AghrewOpM9EB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this project is to develop an image classification algorithm that classifies images into one of two categories."
      ],
      "metadata": {
        "id": "9Znm7z22NBrd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Description"
      ],
      "metadata": {
        "id": "MnWIV944NbLV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset was found from kaggle. The dataset includes images of both birds and drones. We will be using these images to develop an image classification algorithm that determines whether an image is a bird or drone.\n",
        "\n",
        "Link to dataset: https://www.kaggle.com/datasets/harshwalia/birds-vs-drone-dataset/data"
      ],
      "metadata": {
        "id": "qyJIL-ceNc_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries"
      ],
      "metadata": {
        "id": "T1LiW8nHN-3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.io import imread\n",
        "import cv2\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "Pi4SLsikRe2c"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "kVxXnsIwQvSV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22f71415-3b45-4d8b-bc46-bae7eecb1780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting all the jpeg files from the birds and drones folder"
      ],
      "metadata": {
        "id": "oIpqfrvYT8tb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bird = glob.glob(\"/content/drive/MyDrive/bird vs drone/BirdVsDrone/Birds/*.jpeg\")\n",
        "drone = glob.glob(\"/content/drive/MyDrive/bird vs drone/BirdVsDrone/Drones/*.jpeg\")"
      ],
      "metadata": {
        "id": "IEJ6kXiXJETw"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing an empty list to hold the images for both birds and drones"
      ],
      "metadata": {
        "id": "r0lRw4xmUOae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bird_images = []\n",
        "\n",
        "for image in bird:\n",
        "  bird_image = cv2.imread(image)\n",
        "  if bird_image is not None:\n",
        "    bird_images.append(bird_image)"
      ],
      "metadata": {
        "id": "Encl937-RJ4u"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drone_images = []\n",
        "\n",
        "for image in drone:\n",
        "  drone_image = cv2.imread(image)\n",
        "  if drone_image is not None:\n",
        "    drone_images.append(drone_image)"
      ],
      "metadata": {
        "id": "hpF5oOKISdFd"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the amount of images taken from both folders"
      ],
      "metadata": {
        "id": "gwRLfrIW4izA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(bird_images))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9NDJcme0Wob",
        "outputId": "b2626e72-ccad-46f1-c330-d8183c6ba0fb"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(drone_images))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhKjzDAz4nxw",
        "outputId": "6b332924-8726-4fbc-d50f-a8f10580a4eb"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flipping the drone images multiple times to try to balance out the difference in images"
      ],
      "metadata": {
        "id": "Y0Cp1jIZ4uuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rotated_drone_iamges_90_degrees = [np.rot90(image, k=1) for image in drone_images]\n",
        "rotated_drone_images_180_degrees = [np.rot90(image, k=2) for image in drone_images]"
      ],
      "metadata": {
        "id": "g-vv3PMP0ksY"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merging the 3 drone lists together to get one data set and then checking to make sure all 3 lists were added together"
      ],
      "metadata": {
        "id": "qXqBzEyL44HQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_drone_images = drone_images + rotated_drone_iamges_90_degrees + rotated_drone_images_180_degrees"
      ],
      "metadata": {
        "id": "UJRAS21f0oMt"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(merged_drone_images))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JPvzN3a0ZDu",
        "outputId": "32776b2c-3f94-4948-e3f8-335db634fd79"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resizing the bird list so it matches the drones list with random images"
      ],
      "metadata": {
        "id": "_achNyJjmKJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_bird_images = random.sample(bird_images, 342)"
      ],
      "metadata": {
        "id": "MIQvckDwXy4W"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the sizes of an image from both datasets"
      ],
      "metadata": {
        "id": "i9OeEKWDmg87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(balanced_bird_images[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRVg-wGUY8hN",
        "outputId": "af0cff2d-24c7-47af-f5bc-e32f571ae57a"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(275, 183, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(merged_drone_images[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtKstP7xaZ3_",
        "outputId": "0bbfbcfc-60b0-4ff3-ffd2-9fa56604d160"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(168, 299, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing the data type of the images which is a numpy array to PIL image,resizing the images to 128*128, and then changing the data type back to a numpy array"
      ],
      "metadata": {
        "id": "s0vXyIAMm4py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_size = (128, 128)\n",
        "bird_resized = []\n",
        "drone_resized = []\n",
        "\n",
        "for image_array in balanced_bird_images:\n",
        "    image_pil = Image.fromarray(image_array)\n",
        "    resized_image = image_pil.resize(output_size, Image.LANCZOS)\n",
        "    bird_resized.append(np.array(resized_image))\n",
        "\n",
        "for image_array in merged_drone_images:\n",
        "    image_pil = Image.fromarray(image_array)\n",
        "    resized_image = image_pil.resize(output_size, Image.LANCZOS)\n",
        "    drone_resized.append(np.array(resized_image))"
      ],
      "metadata": {
        "id": "-ERkGhW-qtGa"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making sure the sizes of the images changed"
      ],
      "metadata": {
        "id": "a7GVA11Gnscw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(bird_resized[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cLLwEzTnWR8",
        "outputId": "0752cbec-cc42-4f49-c6db-ce2624b472fb"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(drone_resized[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUan3h0hnbjZ",
        "outputId": "c6a8cbd8-2b75-4b6d-fd80-135929a1ab6e"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis"
      ],
      "metadata": {
        "id": "S90dDMUJODp0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combining the two lists together and also giving a label for the images so the image classification algorithm knows which picture is a bird and which is a drone"
      ],
      "metadata": {
        "id": "jgwbkcpB_6mv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_images = np.concatenate((bird_resized, drone_resized), axis=0)\n",
        "labels = np.array([1] * len(bird_resized) + [0] * len(drone_resized))"
      ],
      "metadata": {
        "id": "j246kgViumW9"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing a train test split"
      ],
      "metadata": {
        "id": "QBoBENDjAFsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(all_images, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "UOCKJWqSurdx"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Flattening the images into a 1D array"
      ],
      "metadata": {
        "id": "1a9OkD3utRMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RD1Wzh9DrR2N",
        "outputId": "8673bbb3-8d1d-46c0-a3b4-04a178be4f9f"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(547, 128, 128, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], -1)"
      ],
      "metadata": {
        "id": "MXvOla0Irexn"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_Klcbplr-7T",
        "outputId": "53f59ca7-c9ff-41b6-ae20-07e5a7137430"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(547, 49152)"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = X_test.reshape(X_test.shape[0], -1)"
      ],
      "metadata": {
        "id": "tZQZQ2bTtAiD"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE9MG_d_tGem",
        "outputId": "0171d818-b72e-4c88-f3a2-5fa31de8b777"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(137, 49152)"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Normalizing our train and test data"
      ],
      "metadata": {
        "id": "vwVqnj6btkwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_norm = X_train / 255.0\n",
        "X_test_norm = X_test / 255.0"
      ],
      "metadata": {
        "id": "Yavt-DwDoQUM"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training a classifier using logistic regression"
      ],
      "metadata": {
        "id": "G-lPjO9ut5m9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(\n",
        "                        fit_intercept=True,\n",
        "                        multi_class='auto',\n",
        "                        penalty='l2', #ridge regression\n",
        "                        solver='saga',\n",
        "                        max_iter=100,\n",
        "                        C=50\n",
        "                      )"
      ],
      "metadata": {
        "id": "F-BfR62zt8mO"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the neural network with the training set data."
      ],
      "metadata": {
        "id": "P3AM9XLYuhEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_norm, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "XXqpqKUuuGAD",
        "outputId": "bd1444ea-c853-4aae-9c12-6a878a66b8eb"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=50, solver='saga')"
            ],
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=50, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=50, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making the prediction on the test set, calculating the accuracy, and showing the confusion matrix"
      ],
      "metadata": {
        "id": "0LuYccIJvFbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_norm)\n",
        "accuracy = sum(y_pred == y_test) / len(y_test)\n",
        "print(accuracy)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk9kBgrsuHhf",
        "outputId": "5c60f994-42be-4e49-8698-cb6be70ddb75"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.708029197080292\n",
            "[[31 28]\n",
            " [12 66]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "y0aIGBjBOIO-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From looking at the accuracy, the accuracy when correctly classifying instances from the data set was around 70.8%. A possibility for the accuracy being this low is that the amount of data used in the training set was not a lot. In order to balance the sampling between the bird and drone images, I rotated the drone pictures 90 degrees and 180 degrees to get a larger sample size for the drones. Doing this did increase my accuracy from a 59% accuracy to a 70% accuracy. I believe if I were to find a larger dataset for both birds and drones, I would be able to increase the accuracy for the image classification algorithm. We can see that around 97 out of 137 images were predicted correctly by our image classification algorithm. We can for sure get better results if we were to have a larger training dataset inserted in our neural network. 12 images of birds were falsely identified as a drone which is not bad, however 28 drone images were identified as birds out of 59 which shows that the drone dataset was not diverse enough since I flipped the images multiple times in order to balance out the dataset."
      ],
      "metadata": {
        "id": "U4ByLvoWwz1u"
      }
    }
  ]
}